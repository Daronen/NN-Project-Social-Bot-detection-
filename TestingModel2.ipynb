{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20e13008-6e97-492f-8aaa-5c63cde83430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from transformers import pipeline\n",
    "from datetime import datetime as dt\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b3f4b67-50d0-47c0-b90d-7f9e99e30b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twibot22(Dataset):\n",
    "    def __init__(self,root='./Data/',device='cpu',process=True,save=True):\n",
    "        self.root = root\n",
    "        self.device = device\n",
    "        if process:\n",
    "            print('Loading train.json')\n",
    "            df_train=pd.read_json('./twibot20.json')\n",
    "            self.df_data_labeled=df_train\n",
    "            self.df_data=df_train\n",
    "            self.df_data=self.df_data\n",
    "            self.df_data_labeled=self.df_data_labeled\n",
    "            self.save=save\n",
    "        \n",
    "    def load_labels(self):\n",
    "        print('Loading labels...',end='   ')\n",
    "        path=self.root+'label.pt'\n",
    "        if not os.path.exists(path):\n",
    "            labels=torch.LongTensor(self.df_data_labeled['label']).to(self.device)\n",
    "            if self.save:\n",
    "                torch.save(labels,'./Data/label.pt')\n",
    "        else:\n",
    "            labels=torch.load(self.root+\"label.pt\").to(self.device)\n",
    "        print('Finished')\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def Des_Preprocess(self):\n",
    "        print('Loading raw feature1...',end='   ')\n",
    "        path=self.root+'description.npy'\n",
    "        if not os.path.exists(path):\n",
    "            description=[]\n",
    "            for i in range (self.df_data.shape[0]):\n",
    "                if self.df_data['profile'][i] is None or self.df_data['profile'][i]['description'] is None:\n",
    "                    description.append('None')\n",
    "                else:\n",
    "                    description.append(self.df_data['profile'][i]['description'])\n",
    "            description=np.array(description)\n",
    "            if self.save:\n",
    "                np.save(path,description)\n",
    "        else:\n",
    "            description=np.load(path,allow_pickle=True)\n",
    "        print('Finished')\n",
    "        return description\n",
    "\n",
    "    def Des_embbeding(self):\n",
    "        print('Running feature1 embedding')\n",
    "        path=self.root+\"des_tensor.pt\"\n",
    "        if not os.path.exists(path):\n",
    "            description=np.load(self.root+'description.npy',allow_pickle=True)\n",
    "            print('Loading RoBerta')\n",
    "            feature_extraction = pipeline('feature-extraction', model=\"distilroberta-base\", tokenizer=\"distilroberta-base\",device=0)\n",
    "            des_vec=[]\n",
    "            #for (j,each) in tqdm(enumerate(description)):\n",
    "            for each in tqdm(description):\n",
    "                feature=torch.Tensor(feature_extraction(each))\n",
    "                for (i,tensor) in enumerate(feature[0]):\n",
    "                    if i==0:\n",
    "                        feature_tensor=tensor\n",
    "                    else:\n",
    "                        feature_tensor+=tensor\n",
    "                feature_tensor/=feature.shape[1]\n",
    "                des_vec.append(feature_tensor)\n",
    "                #if (j%1000==0):\n",
    "                    #print('[{:>6d}/229580]'.format(j+1))\n",
    "            des_tensor=torch.stack(des_vec,0).to(self.device)\n",
    "            if self.save:\n",
    "                torch.save(des_tensor,'./Data/des_tensor.pt')\n",
    "        else:\n",
    "            des_tensor=torch.load(self.root+\"des_tensor.pt\").to(self.device)\n",
    "        print('Finished')\n",
    "        return des_tensor\n",
    "    \n",
    "    def tweets_preprocess(self):\n",
    "        print('Loading raw feature2...',end='   ')\n",
    "        path=self.root+'tweets.npy'\n",
    "        if not os.path.exists(path):\n",
    "            tweets=[]\n",
    "            for i in range (self.df_data.shape[0]):\n",
    "                one_usr_tweets=[]\n",
    "                if self.df_data['tweet'][i] is None:\n",
    "                    one_usr_tweets.append('')\n",
    "                else:\n",
    "                    for each in self.df_data['tweet'][i]:\n",
    "                        one_usr_tweets.append(each)\n",
    "                tweets.append(one_usr_tweets)\n",
    "            tweets=np.array(tweets)\n",
    "            if self.save:\n",
    "                np.save(path,tweets)\n",
    "        else:\n",
    "            tweets=np.load(path,allow_pickle=True)\n",
    "        print('Finished')\n",
    "        return tweets\n",
    "    \n",
    "    def tweets_embedding(self):\n",
    "        print('Running feature2 embedding')\n",
    "        path=self.root+\"tweets_tensor.pt\"\n",
    "        if not os.path.exists(path):\n",
    "            tweets=np.load(\"./Data/tweets.npy\",allow_pickle=True)\n",
    "            print('Loading RoBerta')\n",
    "            feature_extract=pipeline('feature-extraction',model='roberta-base',tokenizer='roberta-base',device=0,padding=True, truncation=True,max_length=500, add_special_tokens = True)\n",
    "            tweets_list=[]\n",
    "            for each_person_tweets in tqdm(tweets):\n",
    "                for j,each_tweet in enumerate(each_person_tweets):\n",
    "                    each_tweet_tensor=torch.tensor(feature_extract(each_tweet))\n",
    "                    for k,each_word_tensor in enumerate(each_tweet_tensor[0]):\n",
    "                        if k==0:\n",
    "                            total_word_tensor=each_word_tensor\n",
    "                        else:\n",
    "                            total_word_tensor+=each_word_tensor\n",
    "                    total_word_tensor/=each_tweet_tensor.shape[1]\n",
    "                    if j==0:\n",
    "                        total_each_person_tweets=total_word_tensor\n",
    "                    else:\n",
    "                        total_each_person_tweets+=total_word_tensor\n",
    "                total_each_person_tweets/=len(each_person_tweets)\n",
    "                tweets_list.append(total_each_person_tweets)\n",
    "                #if (i%500==0):\n",
    "                    #print('[{:>6d}/229580]'.format(i+1))\n",
    "            tweet_tensor=torch.stack(tweets_list).to(self.device)\n",
    "            if self.save:\n",
    "                torch.save(tweet_tensor,path)\n",
    "        else:\n",
    "            tweets_tensor=torch.load(self.root+\"tweets_tensor.pt\").to(self.device)\n",
    "        print('Finished')\n",
    "        return tweets_tensor\n",
    "    \n",
    "    def num_prop_preprocess(self):\n",
    "        print('Processing feature3...',end='   ')\n",
    "        path0=self.root+'num_properties_tensor.pt'\n",
    "        if not os.path.exists(path0):\n",
    "            path=self.root\n",
    "            if not os.path.exists(path+\"followers_count.pt\"):\n",
    "                followers_count=[]\n",
    "                for i in range (self.df_data.shape[0]):\n",
    "                    if self.df_data['profile'][i] is None or self.df_data['profile'][i]['followers_count'] is None:\n",
    "                        followers_count.append(0)\n",
    "                    else:\n",
    "                        followers_count.append(self.df_data['profile'][i]['followers_count'])\n",
    "                followers_count=torch.tensor(np.array(followers_count,dtype=np.float32)).to(self.device)\n",
    "                if self.save:\n",
    "                    torch.save(followers_count,path+\"followers_count.pt\")\n",
    "            \n",
    "                friends_count=[]\n",
    "                for i in range (self.df_data.shape[0]):\n",
    "                    if self.df_data['profile'][i] is None or self.df_data['profile'][i]['friends_count'] is None:\n",
    "                        friends_count.append(0)\n",
    "                    else:\n",
    "                        friends_count.append(self.df_data['profile'][i]['friends_count'])\n",
    "                friends_count=torch.tensor(np.array(friends_count,dtype=np.float32)).to(self.device)\n",
    "                if self.save:\n",
    "                    torch.save(friends_count,path+'friends_count.pt')\n",
    "            \n",
    "                screen_name_length=[]\n",
    "                for i in range (self.df_data.shape[0]):\n",
    "                    if self.df_data['profile'][i] is None or self.df_data['profile'][i]['screen_name'] is None:\n",
    "                        screen_name_length.append(0)\n",
    "                    else:\n",
    "                        screen_name_length.append(len(self.df_data['profile'][i]['screen_name']))\n",
    "                screen_name_length=torch.tensor(np.array(screen_name_length,dtype=np.float32)).to(self.device)\n",
    "                if self.save:\n",
    "                    torch.save(screen_name_length,path+'screen_name_length.pt')\n",
    "            \n",
    "                favourites_count=[]\n",
    "                for i in range (self.df_data.shape[0]):\n",
    "                    if self.df_data['profile'][i] is None or self.df_data['profile'][i]['favourites_count'] is None:\n",
    "                        favourites_count.append(0)\n",
    "                    else:\n",
    "                        favourites_count.append(self.df_data['profile'][i]['favourites_count'])\n",
    "                favourites_count=torch.tensor(np.array(favourites_count,dtype=np.float32)).to(self.device)\n",
    "                if self.save:\n",
    "                    torch.save(favourites_count,path+'favourites_count.pt')\n",
    "                \n",
    "                active_days=[]\n",
    "                date0=dt.strptime('Tue Sep 1 00:00:00 +0000 2020 ','%a %b %d %X %z %Y ')\n",
    "                for i in range (self.df_data.shape[0]):\n",
    "                    if self.df_data['profile'][i] is None or self.df_data['profile'][i]['created_at'] is None:\n",
    "                        active_days.append(0)\n",
    "                    else:\n",
    "                        date=dt.strptime(self.df_data['profile'][i]['created_at'],'%a %b %d %X %z %Y ')\n",
    "                        active_days.append((date0-date).days)\n",
    "                active_days=torch.tensor(np.array(active_days,dtype=np.float32)).to(self.device)\n",
    "                if self.save:\n",
    "                    torch.save(active_days,path+'active_days.pt')\n",
    "                \n",
    "                statuses_count=[]\n",
    "                for i in range (self.df_data.shape[0]):\n",
    "                    if self.df_data['profile'][i] is None or self.df_data['profile'][i]['statuses_count'] is None:\n",
    "                        statuses_count.append(0)\n",
    "                    else:\n",
    "                        statuses_count.append(int(self.df_data['profile'][i]['statuses_count']))\n",
    "                statuses_count=torch.tensor(np.array(statuses_count,dtype=np.float32)).to(self.device)\n",
    "                if self.save:\n",
    "                    torch.save(statuses_count,path+'statuses_count.pt')\n",
    "                \n",
    "            else:\n",
    "                active_days=torch.load(path+\"active_days.pt\")\n",
    "                screen_name_length=torch.load(path+\"screen_name_length.pt\")\n",
    "                favourites_count=torch.load(path+\"favourites_count.pt\")\n",
    "                followers_count=torch.load(path+\"followers_count.pt\")\n",
    "                friends_count=torch.load(path+\"friends_count.pt\")\n",
    "                statuses_count=torch.load(path+\"statuses_count.pt\")\n",
    "            \n",
    "            active_days=pd.Series(active_days.to('cpu').detach().numpy())\n",
    "            active_days=(active_days-active_days.mean())/active_days.std()\n",
    "            active_days=torch.tensor(np.array(active_days))\n",
    "\n",
    "            screen_name_length=pd.Series(screen_name_length.to('cpu').detach().numpy())\n",
    "            screen_name_length_days=(screen_name_length-screen_name_length.mean())/screen_name_length.std()\n",
    "            screen_name_length_days=torch.tensor(np.array(screen_name_length_days))\n",
    "\n",
    "            favourites_count=pd.Series(favourites_count.to('cpu').detach().numpy())\n",
    "            favourites_count=(favourites_count-favourites_count.mean())/favourites_count.std()\n",
    "            favourites_count=torch.tensor(np.array(favourites_count))\n",
    "\n",
    "            followers_count=pd.Series(followers_count.to('cpu').detach().numpy())\n",
    "            followers_count=(followers_count-followers_count.mean())/followers_count.std()\n",
    "            followers_count=torch.tensor(np.array(followers_count))\n",
    "\n",
    "            friends_count=pd.Series(friends_count.to('cpu').detach().numpy())\n",
    "            friends_count=(friends_count-friends_count.mean())/friends_count.std()\n",
    "            friends_count=torch.tensor(np.array(friends_count))\n",
    "\n",
    "            statuses_count=pd.Series(statuses_count.to('cpu').detach().numpy())\n",
    "            statuses_count=(statuses_count-statuses_count.mean())/statuses_count.std()\n",
    "            statuses_count=torch.tensor(np.array(statuses_count))\n",
    "\n",
    "            num_prop=torch.cat((followers_count.reshape([229580,1]),friends_count.reshape([229580,1]),favourites_count.reshape([229580,1]),statuses_count.reshape([229580,1]),screen_name_length_days.reshape([229580,1]),active_days.reshape([229580,1])),1).to(self.device)\n",
    "\n",
    "            if self.save:\n",
    "                torch.save(num_prop,\"./Data/num_prop.pt\")\n",
    "            \n",
    "        else:\n",
    "            num_prop=torch.load(self.root+\"num_properties_tensor.pt\").to(self.device)\n",
    "        print('Finished')\n",
    "        return num_prop\n",
    "    \n",
    "    def cat_prop_preprocess(self):\n",
    "        print('Processing feature4...',end='   ')\n",
    "        path=self.root+'cat_properties_tensor.pt'\n",
    "        if not os.path.exists(path):\n",
    "            category_properties=[]\n",
    "            properties=['protected','geo_enabled','verified','contributors_enabled','is_translator','is_translation_enabled','profile_background_tile','profile_use_background_image','has_extended_profile','default_profile','default_profile_image']\n",
    "            for i in range (self.df_data.shape[0]):\n",
    "                prop=[]\n",
    "                if self.df_data['profile'][i] is None:\n",
    "                    for i in range(11):\n",
    "                        prop.append(0)\n",
    "                else:\n",
    "                    for each in properties:\n",
    "                        if self.df_data['profile'][i][each] is None:\n",
    "                            prop.append(0)\n",
    "                        else:\n",
    "                            if self.df_data['profile'][i][each] == \"True \":\n",
    "                                prop.append(1)\n",
    "                            else:\n",
    "                                prop.append(0)\n",
    "                prop=np.array(prop)\n",
    "                category_properties.append(prop)\n",
    "            category_properties=torch.tensor(np.array(category_properties,dtype=np.float32)).to(self.device)\n",
    "            if self.save:\n",
    "                torch.save(category_properties,self.root+'category_properties.pt')\n",
    "        else:\n",
    "            category_properties=torch.load(self.root+\"cat_properties_tensor.pt\").to(self.device)\n",
    "        print('Finished')\n",
    "        return category_properties\n",
    "    \n",
    "    def Build_Graph(self):\n",
    "        print('Building graph',end='   ')\n",
    "        path=self.root+'edge_index.pt'\n",
    "        if not os.path.exists(path):\n",
    "            id2index_dict={id:index for index,id in enumerate(self.df_data['ID'])}\n",
    "            edge_index=[]\n",
    "            edge_type=[]\n",
    "            for i,relation in enumerate(self.df_data['neighbor']):\n",
    "                if relation is not None:\n",
    "                    for each_id in relation['following']:\n",
    "                        try:\n",
    "                            target_id=id2index_dict[int(each_id)]\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "                        else:\n",
    "                            edge_index.append([i,target_id])\n",
    "                        edge_type.append(0)\n",
    "                    for each_id in relation['follower']:\n",
    "                        try:\n",
    "                            target_id=id2index_dict[int(each_id)]\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "                        else:\n",
    "                            edge_index.append([i,target_id])\n",
    "                        edge_type.append(1)\n",
    "                else:\n",
    "                    continue\n",
    "            edge_index=torch.tensor(edge_index,dtype=torch.long).t().contiguous().to(self.device)\n",
    "            edge_type=torch.tensor(edge_type,dtype=torch.long).to(self.device)\n",
    "            if self.save:\n",
    "                torch.save(edge_index,self.root+\"edge_index.pt\")\n",
    "                torch.save(edge_type,self.root+\"edge_type.pt\")\n",
    "        else:\n",
    "            edge_index=torch.load(self.root+\"edge_index.pt\").to(self.device)\n",
    "            edge_type=torch.load(self.root+\"edge_type.pt\").to(self.device)\n",
    "            print('Finished')\n",
    "        return edge_index,edge_type\n",
    "    \n",
    "    def train_val_test_mask(self):\n",
    "        if self.root=='./Data/':\n",
    "            train_idx=range(8278)\n",
    "            val_idx=range(8278,8278+2365)\n",
    "            test_idx=range(8278+2365,8278+2365+1183)\n",
    "        else:\n",
    "            train_idx=torch.load(self.root+'train_idx.pt')\n",
    "            val_idx=torch.load(self.root+'val_idx.pt')\n",
    "            test_idx=torch.load(self.root+'test_idx.pt')\n",
    "            \n",
    "        return train_idx,val_idx,test_idx\n",
    "        \n",
    "        \n",
    "    def dataloader(self):\n",
    "        labels=self.load_labels()\n",
    "        #self.Des_Preprocess()\n",
    "        des_tensor=self.Des_embbeding()\n",
    "        #self.tweets_preprocess()\n",
    "        tweets_tensor=self.tweets_embedding()\n",
    "        num_prop=self.num_prop_preprocess()\n",
    "        category_prop=self.cat_prop_preprocess()\n",
    "        edge_index,edge_type=self.Build_Graph()\n",
    "        train_idx,val_idx,test_idx=self.train_val_test_mask()\n",
    "        return des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type,labels,train_idx,val_idx,test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0aa7527f-9553-40d1-846c-438121d7b64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.json\n"
     ]
    }
   ],
   "source": [
    "dataset=Twibot22(root='./Data20/',device='cpu',process=True,save=True)\n",
    "#des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type,labels,train_idx,val_idx,test_idx=dataset.dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a92c1ff9-21ae-4be5-abb7-e54c870c0235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukez\\AppData\\Local\\Temp\\ipykernel_23332\\4132212342.py:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['created_at'] = pd.to_datetime(df['created_at'])\n",
      "C:\\Users\\lukez\\AppData\\Local\\Temp\\ipykernel_23332\\4132212342.py:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['created_at'] = pd.to_datetime(df['created_at'])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "bot_accounts = pd.concat([pd.read_csv('data/social_spambots_1.csv'), pd.read_csv('data/social_spambots_2.csv'), pd.read_csv('data/social_spambots_3.csv')]).reset_index(drop=True)\n",
    "clean_accounts = pd.read_csv('data/geniune_accounts.csv')\n",
    "\n",
    "requiredColumns = ['screen_name', 'created_at', 'updated', 'location', 'verified', 'statuses_count', 'friends_count','followers_count', 'favourites_count', 'default_profile_image', 'profile_use_background_image', 'protected', 'default_profile']\n",
    "bot_accounts = bot_accounts#[requiredColumns]\n",
    "clean_accounts = clean_accounts#[requiredColumns]\n",
    "\n",
    "def clean_df(df):\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['updated'] = pd.to_datetime(df['updated'])\n",
    "    #print(df['updated'])\n",
    "    #print()\n",
    "    #print(df['created_at'])\n",
    "    df['age'] = ((df['updated'].dt.tz_localize('UTC') - df['created_at']) / np.timedelta64(1, 'D')).astype('int') #modified this line from original repo code.\n",
    "    #df['age'] = (df['updated'].dt.tz_localize('UTC') - df['created_at']).astype('timedelta64[D]').astype(int)\n",
    "    #print(df['age'])\n",
    "    df['has_location'] = df['location'].apply(lambda x: 0 if x==x else 1)\n",
    "    df['has_avatar'] = df['default_profile_image'].apply(lambda x: 1 if x==x else 0)\n",
    "    df['has_background'] = df['profile_use_background_image'].apply(lambda x: 1 if x==x else 0)\n",
    "    df['is_verified']=df['verified'].apply(lambda x: 1 if x==x else 0)\n",
    "    df['is_protected']=df['protected'].apply(lambda x: 1 if x==x else 0)\n",
    "    df['profile_modified'] = df['default_profile'].apply(lambda x: 0 if x==x else 1)\n",
    "\n",
    "    #properties=['protected','geo_enabled','verified','contributors_enabled','is_translator','is_translation_enabled','profile_background_tile','profile_use_background_image','has_extended_profile','default_profile','default_profile_image']\n",
    "    \n",
    "    return df[['screen_name', 'age', 'has_location', 'is_verified', 'statuses_count', 'friends_count', 'followers_count', 'favourites_count', 'has_avatar', 'has_background', 'is_protected', 'profile_modified', 'protected', 'geo_enabled','verified','contributors_enabled','is_translator','profile_background_tile','profile_use_background_image','default_profile','default_profile_image', 'description']]\n",
    "\n",
    "bot_accounts = clean_df(bot_accounts)\n",
    "clean_accounts = clean_df(clean_accounts)\n",
    "\n",
    "bot_accounts['BotOrNot'] = 1\n",
    "clean_accounts['BotOrNot'] = 0\n",
    "\n",
    "combined_df = pd.concat([bot_accounts, clean_accounts], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c35cfbc5-499e-4ded-a3f5-4f7c571aef15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>age</th>\n",
       "      <th>has_location</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>has_avatar</th>\n",
       "      <th>has_background</th>\n",
       "      <th>...</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>verified</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>is_translator</th>\n",
       "      <th>profile_background_tile</th>\n",
       "      <th>profile_use_background_image</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>description</th>\n",
       "      <th>BotOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>davideb66</td>\n",
       "      <td>2555</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1299</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElisaDospina</td>\n",
       "      <td>2521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18665</td>\n",
       "      <td>3442</td>\n",
       "      <td>12561</td>\n",
       "      <td>16358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Autrice del libro #unavitatuttacurve dal 9 apr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vladimir65</td>\n",
       "      <td>2497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22987</td>\n",
       "      <td>755</td>\n",
       "      <td>600</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Live Long and Prosper]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RafielaMorales</td>\n",
       "      <td>2435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7975</td>\n",
       "      <td>350</td>\n",
       "      <td>398</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cuasi Odontologa*♥,#Bipolar, #Sarcastica &amp; Som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FabrizioC_c</td>\n",
       "      <td>2413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20218</td>\n",
       "      <td>405</td>\n",
       "      <td>413</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I shall rise from my own death, to avenge hers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      screen_name   age  has_location  is_verified  statuses_count  \\\n",
       "0       davideb66  2555             1            0            1299   \n",
       "1    ElisaDospina  2521             0            0           18665   \n",
       "2      Vladimir65  2497             0            0           22987   \n",
       "3  RafielaMorales  2435             0            0            7975   \n",
       "4     FabrizioC_c  2413             0            0           20218   \n",
       "\n",
       "   friends_count  followers_count  favourites_count  has_avatar  \\\n",
       "0             40               22                 1           1   \n",
       "1           3442            12561             16358           0   \n",
       "2            755              600                14           0   \n",
       "3            350              398                11           0   \n",
       "4            405              413               162           0   \n",
       "\n",
       "   has_background  ...  geo_enabled  verified  contributors_enabled  \\\n",
       "0               1  ...          1.0       NaN                   NaN   \n",
       "1               1  ...          1.0       NaN                   NaN   \n",
       "2               1  ...          NaN       NaN                   NaN   \n",
       "3               1  ...          NaN       NaN                   NaN   \n",
       "4               1  ...          1.0       NaN                   NaN   \n",
       "\n",
       "   is_translator  profile_background_tile  profile_use_background_image  \\\n",
       "0            NaN                      NaN                           1.0   \n",
       "1            NaN                      1.0                           1.0   \n",
       "2            NaN                      1.0                           1.0   \n",
       "3            NaN                      1.0                           1.0   \n",
       "4            NaN                      NaN                           1.0   \n",
       "\n",
       "   default_profile  default_profile_image  \\\n",
       "0              1.0                    1.0   \n",
       "1              NaN                    NaN   \n",
       "2              NaN                    NaN   \n",
       "3              NaN                    NaN   \n",
       "4              NaN                    NaN   \n",
       "\n",
       "                                         description  BotOrNot  \n",
       "0                                                NaN         1  \n",
       "1  Autrice del libro #unavitatuttacurve dal 9 apr...         1  \n",
       "2                            [Live Long and Prosper]         1  \n",
       "3  Cuasi Odontologa*♥,#Bipolar, #Sarcastica & Som...         1  \n",
       "4  I shall rise from my own death, to avenge hers...         1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_accounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8aabe95b-54b0-45d0-94c8-e65fafdc267f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>age</th>\n",
       "      <th>has_location</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>has_avatar</th>\n",
       "      <th>has_background</th>\n",
       "      <th>...</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>verified</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>is_translator</th>\n",
       "      <th>profile_background_tile</th>\n",
       "      <th>profile_use_background_image</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>description</th>\n",
       "      <th>BotOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0918Bask</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2177</td>\n",
       "      <td>332</td>\n",
       "      <td>208</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15years ago X.Lines24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1120Roll</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2660</td>\n",
       "      <td>485</td>\n",
       "      <td>330</td>\n",
       "      <td>3972</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>保守見習い地元大好き人間。 経済学、電工、仏教を勉強中、ちなDeではいかんのか？ (*^◯^*)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14KBBrown</td>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1254</td>\n",
       "      <td>177</td>\n",
       "      <td>166</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Let me see what your best move is!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wadespeters</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202968</td>\n",
       "      <td>981</td>\n",
       "      <td>2248</td>\n",
       "      <td>60304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20. menna: #farida #nyc and the 80s actually y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191a5bd05da04dc</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cosmetologist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name   age  has_location  is_verified  statuses_count  \\\n",
       "0         0918Bask  1008             0            0            2177   \n",
       "1         1120Roll   672             0            0            2660   \n",
       "2        14KBBrown  1776             1            0            1254   \n",
       "3      wadespeters  2006             0            0          202968   \n",
       "4  191a5bd05da04dc   403             0            0              82   \n",
       "\n",
       "   friends_count  followers_count  favourites_count  has_avatar  \\\n",
       "0            332              208               265           0   \n",
       "1            485              330              3972           0   \n",
       "2            177              166              1185           0   \n",
       "3            981             2248             60304           0   \n",
       "4             79               21                 5           0   \n",
       "\n",
       "   has_background  ...  geo_enabled  verified  contributors_enabled  \\\n",
       "0               0  ...          1.0       NaN                   NaN   \n",
       "1               1  ...          1.0       NaN                   NaN   \n",
       "2               1  ...          NaN       NaN                   NaN   \n",
       "3               1  ...          1.0       NaN                   NaN   \n",
       "4               1  ...          NaN       NaN                   NaN   \n",
       "\n",
       "   is_translator  profile_background_tile  profile_use_background_image  \\\n",
       "0            NaN                      NaN                           NaN   \n",
       "1            NaN                      NaN                           1.0   \n",
       "2            NaN                      1.0                           1.0   \n",
       "3            NaN                      NaN                           1.0   \n",
       "4            NaN                      NaN                           1.0   \n",
       "\n",
       "   default_profile  default_profile_image  \\\n",
       "0              NaN                    NaN   \n",
       "1              1.0                    NaN   \n",
       "2              NaN                    NaN   \n",
       "3              NaN                    NaN   \n",
       "4              1.0                    NaN   \n",
       "\n",
       "                                         description  BotOrNot  \n",
       "0                              15years ago X.Lines24         0  \n",
       "1   保守見習い地元大好き人間。 経済学、電工、仏教を勉強中、ちなDeではいかんのか？ (*^◯^*)         0  \n",
       "2                 Let me see what your best move is!         0  \n",
       "3  20. menna: #farida #nyc and the 80s actually y...         0  \n",
       "4                                      Cosmetologist         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_accounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "959849d6-407f-44c4-82ad-81f65ab31185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8386"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35667cab-a153-4b23-a92f-498e9094f8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"followers_count\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cdfa13e-8b07-4b0f-b8fc-e79ab3a69dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels1(df, root='./Data/', save=True, device='cpu'):\n",
    "    print('Loading labels...',end='   ')\n",
    "    path=root+'label.pt'\n",
    "    if not os.path.exists(path):\n",
    "        labels=torch.LongTensor(df['BotOrNot']).to(device)\n",
    "        if save:\n",
    "            torch.save(labels,'./Data/label.pt')\n",
    "    else:\n",
    "        labels=torch.load(root+\"label.pt\").to(device)\n",
    "    print('Finished')\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa7c32f2-39f6-4148-86a4-5ed875c652d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Des_Preprocess1(df, root='./Data/', save=True, device='cpu'):\n",
    "    print('Loading raw feature1...',end='   ')\n",
    "    path=root+'description.npy'\n",
    "    if not os.path.exists(path):\n",
    "        description=[]\n",
    "        for i in range (df.shape[0]):\n",
    "            if df['description'][i] is None:\n",
    "                description.append('None')\n",
    "            else:\n",
    "                description.append(df['description'][i])\n",
    "        description=np.array(description)\n",
    "        if save:\n",
    "            np.save(path,description)\n",
    "    else:\n",
    "        description=np.load(path,allow_pickle=True)\n",
    "    print('Finished')\n",
    "    return description\n",
    "\n",
    "def Des_embbeding1(root='./Data/', save=True, device='cpu'):\n",
    "    print('Running feature1 embedding')\n",
    "    path=root+\"des_tensor.pt\"\n",
    "    if not os.path.exists(path):\n",
    "        description=np.load(root+'description.npy',allow_pickle=True)\n",
    "        print('Loading RoBerta')\n",
    "        feature_extraction = pipeline('feature-extraction', model=\"distilroberta-base\", tokenizer=\"distilroberta-base\",device=0)\n",
    "        des_vec=[]\n",
    "        #for (j,each) in tqdm(enumerate(description)):\n",
    "        for each in tqdm(description):\n",
    "            feature=torch.Tensor(feature_extraction(each))\n",
    "            for (i,tensor) in enumerate(feature[0]):\n",
    "                if i==0:\n",
    "                    feature_tensor=tensor\n",
    "                else:\n",
    "                    feature_tensor+=tensor\n",
    "            feature_tensor/=feature.shape[1]\n",
    "            des_vec.append(feature_tensor)\n",
    "            #if (j%1000==0):\n",
    "                #print('[{:>6d}/229580]'.format(j+1))\n",
    "        des_tensor=torch.stack(des_vec,0).to(device)\n",
    "        if save:\n",
    "            torch.save(des_tensor,'./Data/des_tensor.pt')\n",
    "    else:\n",
    "        des_tensor=torch.load(root+\"des_tensor.pt\").to(device)\n",
    "    print('Finished')\n",
    "    return des_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48e26c87-d27d-4242-9513-7cb5bcd1ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_preprocess1(df, root='./Data/', save=True, device='cpu'):\n",
    "    print('Loading raw feature2...',end='   ')\n",
    "    path=root+'tweets.npy'\n",
    "    if not os.path.exists(path):\n",
    "        tweets=[]\n",
    "        for i in range(df.shape[0]):\n",
    "            one_usr_tweets=[]\n",
    "            one_usr_tweets.append('')\n",
    "            tweets.append(one_usr_tweets)\n",
    "        tweets=np.array(tweets)\n",
    "        if save:\n",
    "            np.save(path,tweets)\n",
    "    else:\n",
    "        tweets=np.load(path,allow_pickle=True)\n",
    "    print('Finished')\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4dc2c216-56ea-4f64-ac31-11ce6cdc626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_embedding1(root='./Data/', save=True, device='cpu'):\n",
    "    print('Running feature2 embedding')\n",
    "    path=root+\"tweets_tensor.pt\"\n",
    "    if not os.path.exists(path):\n",
    "        tweets=np.load(\"./Data/tweets.npy\",allow_pickle=True)\n",
    "        print('Loading RoBerta')\n",
    "        feature_extract=pipeline('feature-extraction',model='roberta-base',tokenizer='roberta-base',device=0,padding=True, truncation=True,max_length=500, add_special_tokens = True)\n",
    "        print(\"pipeline Done\")\n",
    "        tweets_list=[]\n",
    "        for each_person_tweets in tqdm(tweets):\n",
    "            for j,each_tweet in enumerate(each_person_tweets):\n",
    "                print(\"j:\", j)\n",
    "                each_tweet_tensor=torch.tensor(feature_extract(each_tweet))\n",
    "                for k,each_word_tensor in enumerate(each_tweet_tensor[0]):\n",
    "                    if k==0:\n",
    "                        total_word_tensor=each_word_tensor\n",
    "                    else:\n",
    "                        total_word_tensor+=each_word_tensor\n",
    "                total_word_tensor/=each_tweet_tensor.shape[1]\n",
    "                if j==0:\n",
    "                    total_each_person_tweets=total_word_tensor\n",
    "                else:\n",
    "                    total_each_person_tweets+=total_word_tensor\n",
    "            total_each_person_tweets/=len(each_person_tweets)\n",
    "            tweets_list.append(total_each_person_tweets)\n",
    "            #if (i%500==0):\n",
    "                #print('[{:>6d}/229580]'.format(i+1))\n",
    "        tweet_tensor=torch.stack(tweets_list).to(device)\n",
    "        if save:\n",
    "            torch.save(tweet_tensor,path)\n",
    "    else:\n",
    "        tweets_tensor=torch.load(root+\"tweets_tensor.pt\").to(device)\n",
    "    print('Finished')\n",
    "    return tweets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f13b9bae-86d2-432b-a8af-f32bacf2e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_prop_preprocess1(df, root='./Data/', save=True, device='cpu'):\n",
    "    print('Processing feature3...',end='   ')\n",
    "    path0=root+'num_properties_tensor.pt'\n",
    "    if not os.path.exists(path0):\n",
    "        path=root\n",
    "        if not os.path.exists(path+\"followers_count.pt\"):\n",
    "            followers_count=[]\n",
    "            for i in range(df.shape[0]):\n",
    "                if  df['followers_count'][i] is None:\n",
    "                    followers_count.append(0)\n",
    "                else:\n",
    "                    followers_count.append(df['followers_count'][i])\n",
    "            followers_count=torch.tensor(np.array(followers_count,dtype=np.float32)).to(device)\n",
    "            if save:\n",
    "                torch.save(followers_count,path+\"followers_count.pt\")\n",
    "        \n",
    "            friends_count=[]\n",
    "            for i in range (df.shape[0]):\n",
    "                if  df['friends_count'][i] is None:\n",
    "                    friends_count.append(0)\n",
    "                else:\n",
    "                    friends_count.append(df['friends_count'][i])\n",
    "            friends_count=torch.tensor(np.array(friends_count,dtype=np.float32)).to(device)\n",
    "            if save:\n",
    "                torch.save(friends_count,path+'friends_count.pt')\n",
    "        \n",
    "            screen_name_length=[]\n",
    "            for i in range (df.shape[0]):\n",
    "                if  df['screen_name'][i] is None:\n",
    "                    screen_name_length.append(0)\n",
    "                else:\n",
    "                    screen_name_length.append(len(df['screen_name'][i]))\n",
    "            screen_name_length=torch.tensor(np.array(screen_name_length,dtype=np.float32)).to(device)\n",
    "            if save:\n",
    "                torch.save(screen_name_length,path+'screen_name_length.pt')\n",
    "        \n",
    "            favourites_count=[]\n",
    "            for i in range (df.shape[0]):\n",
    "                if  df['favourites_count'][i] is None:\n",
    "                    favourites_count.append(0)\n",
    "                else:\n",
    "                    favourites_count.append(df['favourites_count'][i])\n",
    "            favourites_count=torch.tensor(np.array(favourites_count,dtype=np.float32)).to(device)\n",
    "            if save:\n",
    "                torch.save(favourites_count,path+'favourites_count.pt')\n",
    "            \n",
    "            active_days=[]\n",
    "            for i in range (df.shape[0]):\n",
    "                if  df['age'][i] is None:\n",
    "                    active_days.append(0)\n",
    "                else:\n",
    "                    active_days.append(df['age'][i])\n",
    "            active_days=torch.tensor(np.array(active_days,dtype=np.float32)).to(device)\n",
    "            if save:\n",
    "                torch.save(active_days,path+'active_days.pt')\n",
    "            \n",
    "            statuses_count=[]\n",
    "            for i in range (df.shape[0]):\n",
    "                if  df['statuses_count'][i] is None:\n",
    "                    statuses_count.append(0)\n",
    "                else:\n",
    "                    statuses_count.append(int(df['statuses_count'][i]))\n",
    "            statuses_count=torch.tensor(np.array(statuses_count,dtype=np.float32)).to(device)\n",
    "            if save:\n",
    "                torch.save(statuses_count,path+'statuses_count.pt')\n",
    "            \n",
    "        else:\n",
    "            active_days=torch.load(path+\"active_days.pt\")\n",
    "            screen_name_length=torch.load(path+\"screen_name_length.pt\")\n",
    "            favourites_count=torch.load(path+\"favourites_count.pt\")\n",
    "            followers_count=torch.load(path+\"followers_count.pt\")\n",
    "            friends_count=torch.load(path+\"friends_count.pt\")\n",
    "            statuses_count=torch.load(path+\"statuses_count.pt\")\n",
    "        \n",
    "        active_days=pd.Series(active_days.to('cpu').detach().numpy())\n",
    "        active_days=(active_days-active_days.mean())/active_days.std()\n",
    "        active_days=torch.tensor(np.array(active_days))\n",
    "\n",
    "        screen_name_length=pd.Series(screen_name_length.to('cpu').detach().numpy())\n",
    "        screen_name_length_days=(screen_name_length-screen_name_length.mean())/screen_name_length.std()\n",
    "        screen_name_length_days=torch.tensor(np.array(screen_name_length_days))\n",
    "\n",
    "        favourites_count=pd.Series(favourites_count.to('cpu').detach().numpy())\n",
    "        favourites_count=(favourites_count-favourites_count.mean())/favourites_count.std()\n",
    "        favourites_count=torch.tensor(np.array(favourites_count))\n",
    "\n",
    "        followers_count=pd.Series(followers_count.to('cpu').detach().numpy())\n",
    "        followers_count=(followers_count-followers_count.mean())/followers_count.std()\n",
    "        followers_count=torch.tensor(np.array(followers_count))\n",
    "\n",
    "        friends_count=pd.Series(friends_count.to('cpu').detach().numpy())\n",
    "        friends_count=(friends_count-friends_count.mean())/friends_count.std()\n",
    "        friends_count=torch.tensor(np.array(friends_count))\n",
    "\n",
    "        statuses_count=pd.Series(statuses_count.to('cpu').detach().numpy())\n",
    "        statuses_count=(statuses_count-statuses_count.mean())/statuses_count.std()\n",
    "        statuses_count=torch.tensor(np.array(statuses_count))\n",
    "\n",
    "        #print(\"followers_count shape:\", followers_count.shape)\n",
    "        #print(\"friends_count shape:\", friends_count.shape)\n",
    "        #print(\"favourites_count shape:\", favourites_count.shape)\n",
    "        #print(\"statuses_count shape:\", statuses_count.shape)\n",
    "        #print(\"screen_name_length_days shape:\", screen_name_length_days.shape)\n",
    "        #print(\"active_days shape:\", active_days.shape)\n",
    "        #num_properties_tensor=torch.cat([followers_count,active_days,screen_name_length,following_count,statues],dim=1)\n",
    "        num_prop=torch.cat((followers_count.reshape([df.shape[0],1]),\n",
    "                            active_days.reshape([df.shape[0],1]),\n",
    "                            screen_name_length_days.reshape([df.shape[0],1]),\n",
    "                            friends_count.reshape([df.shape[0],1]),\n",
    "                            statuses_count.reshape([df.shape[0],1])),1).to(device)\n",
    "\n",
    "        \n",
    "        #num_prop=torch.cat((followers_count.reshape([df.shape[0],1]),friends_count.reshape([df.shape[0],1]),favourites_count.reshape([df.shape[0],1]),statuses_count.reshape([df.shape[0],1]),screen_name_length_days.reshape([df.shape[0],1]),active_days.reshape([df.shape[0],1])),1).to(device)\n",
    "\n",
    "        if save:\n",
    "            torch.save(num_prop,\"./Data/num_prop.pt\")\n",
    "        \n",
    "    else:\n",
    "        num_prop=torch.load(root+\"num_properties_tensor.pt\").to(device)\n",
    "    print('Finished')\n",
    "    return num_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "add26845-9523-41ea-95cd-0910aeadb4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_prop_preprocess1(df, root='./Data/', save=True, device='cpu'):\n",
    "    print('Processing feature4...',end='   ')\n",
    "    path=root+'cat_properties_tensor.pt'\n",
    "    if not os.path.exists(path):\n",
    "        category_properties=[]\n",
    "        #properties=['protected','geo_enabled','verified','contributors_enabled','is_translator','is_translation_enabled','profile_background_tile','profile_use_background_image','has_extended_profile','default_profile','default_profile_image']\n",
    "        properties=['default_profile_image']\n",
    "        for i in range (df.shape[0]):\n",
    "            prop=[]\n",
    "            for each in properties:\n",
    "                if each == 'is_translation_enabled' or each == 'has_extended_profile':\n",
    "                    prop.append(0)\n",
    "                else:\n",
    "                    if df[each][i] is None:\n",
    "                        prop.append(0)\n",
    "                    else:\n",
    "                        if df[each][i] == 1:\n",
    "                            prop.append(1)\n",
    "                        else:\n",
    "                            prop.append(0)\n",
    "            prop=np.array(prop)\n",
    "            category_properties.append(prop)\n",
    "        category_properties=torch.tensor(np.array(category_properties,dtype=np.float32)).reshape([df.shape[0],1]).to(device)\n",
    "        if save:\n",
    "            torch.save(category_properties,root+'category_properties.pt')\n",
    "    else:\n",
    "        category_properties=torch.load(root+\"cat_properties_tensor.pt\").to(device)\n",
    "    print('Finished')\n",
    "    return category_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f8bb721-c084-4b1a-80b3-292adf9c4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Graph1(root='./Data/', save=True, device='cpu'):\n",
    "        print('Building graph',end='   ')\n",
    "        path=root+'edge_index0.pt'\n",
    "        if not os.path.exists(path):\n",
    "            edge_index=torch.empty(2, 0)\n",
    "            edge_type=[]\n",
    "            #edge_index.append(0,0)\n",
    "            #edge_index.append([[],[]])\n",
    "            edge_index=torch.tensor(edge_index,dtype=torch.long).t().contiguous().to(device)\n",
    "            edge_type=torch.tensor(edge_type,dtype=torch.long).to(device)\n",
    "            if save:\n",
    "                torch.save(edge_index,root+\"edge_index.pt\")\n",
    "                torch.save(edge_type,root+\"edge_type.pt\")\n",
    "        else:\n",
    "            edge_index=torch.load(root+\"edge_index.pt\").to(device)\n",
    "            edge_type=torch.load(root+\"edge_type.pt\").to(device)\n",
    "            print('Finished')\n",
    "        return edge_index,edge_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "731d54f7-214c-46c3-9c71-b3c0e14a0745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels...   Finished\n",
      "torch.Size([8386])\n"
     ]
    }
   ],
   "source": [
    "labels=load_labels1(combined_df)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ebf963be-56db-4aba-aac6-934b5637d862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw feature1...   Finished\n",
      "Running feature1 embedding\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "Des_Preprocess1(combined_df)\n",
    "des_tensor=Des_embbeding1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b550e0e4-ef57-4f20-954a-40aa4a84b394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw feature2...   Finished\n",
      "Running feature2 embedding\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "tweets_preprocess1(combined_df)\n",
    "tweets_tensor=tweets_embedding1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0900905d-9e49-48aa-b9ba-fa7668a1d968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature3...   Finished\n",
      "torch.Size([8386, 5])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_prop1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_prop\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#num_prop1=num_prop_preprocess1(combined_df)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_prop1\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_prop1' is not defined"
     ]
    }
   ],
   "source": [
    "num_prop=num_prop_preprocess1(combined_df)\n",
    "print(num_prop.shape)\n",
    "\n",
    "#num_prop1=num_prop_preprocess1(combined_df)\n",
    "#print(num_prop1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4840ec-a7d5-4186-a4b5-034dadeb25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_prop=cat_prop_preprocess1(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d64fb-7935-44a1-afe0-178437eaf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index,edge_type=Build_Graph1()\n",
    "edge_index=torch.empty(2, 0).type(torch.int)\n",
    "print(edge_index)\n",
    "print(edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e64df8-425d-46b8-99a5-488783dc67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1,edge_type1=Build_Graph1()\n",
    "print(edge_index1)\n",
    "print(edge_type1)\n",
    "unique_values, counts = torch.unique(edge_index1, return_counts=True)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c33355-1341-497f-9d3c-1e8ba1e3bcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f66574-0cb3-4664-b4bc-04c03bb4633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx1=torch.load('./Data/'+'train_idx.pt')\n",
    "val_idx1=torch.load('./Data/'+'val_idx.pt')\n",
    "test_idx1=torch.load('./Data/'+'test_idx.pt')\n",
    "\n",
    "index = []\n",
    "for i in range(num_prop.shape[0]):\n",
    "    #print(i)\n",
    "    index.append(i)\n",
    "\n",
    "index_tens = torch.tensor(index) \n",
    "print(index_tens.shape)\n",
    "print(index_tens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d86d01-a44b-4620-bb06-14d1458cadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import RGCNConv,FastRGCNConv,GCNConv,GATConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BotRGCN(nn.Module):\n",
    "    def __init__(self,des_size=768,tweet_size=768,num_prop_size=5,cat_prop_size=3,embedding_dimension=128,dropout=0.3):\n",
    "        super(BotRGCN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.linear_relu_des=nn.Sequential(\n",
    "            nn.Linear(des_size,int(embedding_dimension/4)),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.linear_relu_tweet=nn.Sequential(\n",
    "            nn.Linear(tweet_size,int(embedding_dimension/4)),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.linear_relu_num_prop=nn.Sequential(\n",
    "            nn.Linear(num_prop_size,int(embedding_dimension/4)),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.linear_relu_cat_prop=nn.Sequential(\n",
    "            nn.Linear(cat_prop_size,int(embedding_dimension/4)),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear_relu_input=nn.Sequential(\n",
    "            nn.Linear(embedding_dimension,embedding_dimension),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.rgcn=RGCNConv(embedding_dimension,embedding_dimension,num_relations=2)\n",
    "        \n",
    "        self.linear_relu_output1=nn.Sequential(\n",
    "            nn.Linear(embedding_dimension,embedding_dimension),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.linear_output2=nn.Linear(embedding_dimension,2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,des,tweet,num_prop,cat_prop,edge_index,edge_type):\n",
    "        d=self.linear_relu_des(des)\n",
    "        t=self.linear_relu_tweet(tweet)\n",
    "        n=self.linear_relu_num_prop(num_prop)\n",
    "        c=self.linear_relu_cat_prop(cat_prop)\n",
    "        x=torch.cat((d,t,n,c),dim=1)\n",
    "        \n",
    "        x=self.linear_relu_input(x)\n",
    "        x=self.rgcn(x,edge_index,edge_type)\n",
    "        x=F.dropout(x,p=self.dropout,training=self.training)\n",
    "        x=self.rgcn(x,edge_index,edge_type)\n",
    "        x=self.linear_relu_output1(x)\n",
    "        x=self.linear_output2(x)\n",
    "            \n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391116b0-8583-4645-a287-a29665052d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size,dropout,lr,weight_decay=32,0.1,1e-2,5e-2\n",
    "\n",
    "model=BotRGCN(cat_prop_size=1,embedding_dimension=embedding_size).to('cpu')\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                    lr=lr,weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f9a6a-9721-4655-85fb-9eff4c028557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.kaiming_uniform_(m.weight)\n",
    "\n",
    "\n",
    "def test(test_idx):\n",
    "    model.eval()\n",
    "    output = model(des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type)\n",
    "    loss_test = loss(output[test_idx], labels[test_idx])\n",
    "    acc_test = accuracy(output[test_idx], labels[test_idx])\n",
    "    output=output.max(1)[1].to('cpu').detach().numpy()\n",
    "    label=labels.to('cpu').detach().numpy()\n",
    "    f1=f1_score(label[test_idx],output[test_idx])\n",
    "    #mcc=matthews_corrcoef(label[test_idx], output[test_idx])\n",
    "    precision=precision_score(label[test_idx],output[test_idx])\n",
    "    recall=recall_score(label[test_idx],output[test_idx])\n",
    "    fpr, tpr, thresholds = roc_curve(label[test_idx], output[test_idx], pos_label=1)\n",
    "    Auc=auc(fpr, tpr)\n",
    "    print(\"Test set results:\",\n",
    "            \"test_loss= {:.4f}\".format(loss_test.item()),\n",
    "            \"test_accuracy= {:.4f}\".format(acc_test.item()),\n",
    "            \"precision= {:.4f}\".format(precision.item()),\n",
    "            \"recall= {:.4f}\".format(recall.item()),\n",
    "            \"f1_score= {:.4f}\".format(f1.item()),\n",
    "            #\"mcc= {:.4f}\".format(mcc.item()),\n",
    "            \"auc= {:.4f}\".format(Auc.item()),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24018360-cbfb-40ea-91f9-aa22aee6df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('BotRGCN_weight.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645e05e-fc5c-4aac-9d88-12dd76ce9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(index_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bef39a-e73c-4599-9bfe-f6627a8e37e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283f02a-83d7-4bc1-9e4c-b2341a5188c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
